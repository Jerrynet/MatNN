function net = testbuildnet( baseNet )
%TESTBUILDNET Summary of this function goes here
%   Detailed explanation goes here

no = nn.buildnet('testNet', baseNet);

% Data Top Size
no.setDataBlobSize('data' , [227 227 3    128]);
no.setDataBlobSize('label', [1   1   96   128]); 

no.newLayer({
            'type'         'layers.convolution'          ...
            'name'         'conv1'                       ...
            'bottom'       {'data'}                      ...
            'top'          {'conv1'}                     ...
            'convolution_param' {
                           'num_output'   96             ...
                           'kernel_size'  [3 3]          ...
                           'stride'       4              ...
                           'pad'          0
            }...
            'weight_param' {
                           'name'         {'w1', 'b1'}   ...
                           'enable_terms' [true, false]  ... % this means don't use bias term
                           'generator'    {@rand, @rand} ...
                           'learningRate' [1 2]          ...
                           'weightDecay'  [1 0]
            }
            });
no.newLayer({
            'type'         'layers.relu'                 ...
            'name'         'relu1'                       ...
            'bottom'       {'conv1'}                     ...
            'top'          {'relu1'}                     ...
            });
no.newLayer({
            'type'         'layers.pooling'              ...
            'name'         'pool1'                       ...
            'bottom'       {'relu1'}                     ...
            'top'          {'pool1'}                     ...
            });
no.newLayer({
            'type'         'layers.convolution'          ...
            'name'         'conv2'                       ...
            'bottom'       {'pool1'}                     ...
            'top'          {'conv2'}                     ...
            'convolution_param' {
                           'num_output'   96             ...
                           'kernel_size'  [3 3]          ...
                           'stride'       4              ...
                           'pad'          0
            }...
            'weight_param' {
                           'generator'    {@rand, @rand} ...
                           'learningRate' [1 2]          ...
                           'weightDecay'  [1 0]
            }
            });
no.newLayer({
            'type'         'layers.loss.softmaxLoss'     ...
            'name'         'loss'                        ...
            'bottom'       {'conv2', 'label'}            ...
            'top'          {'loss'}                      ...
            });
        
        
net = no.getNet('train');
end

