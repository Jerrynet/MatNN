classdef hasWeight < handle

     % Default parameters
    properties (SetAccess = protected, Transient)
        default_weight_param = {
                'name' {'', ''}         ... %empty names means use autogenerated name
        'enable_terms' [true, true]     ... 
           'generator' {@nn.generator.uniform, @nn.generator.constant} ...
           'generator_param' {[], []}   ... %default param
        'learningRate' single([1 1])    ...
         'weightDecay' single([1 1])
        };
    end

    % if weights_diff_isCumulate(1) && weights_diff_isCumulate(2)
    %         [ bottom_diff{1}, a, b ]= ...
    %                          vl_nnconv(bottom{1}, weights{1}, weights{2}, top_diff{1}, 'pad', l.convolution_param.pad, 'stride', l.convolution_param.stride);
    %         weights_diff{1} = weights_diff{1} + a;
    %         weights_diff{2} = weights_diff{2} + b;
    %     elseif weights_diff_isCumulate(1)
    %         [ bottom_diff{1}, outputdzdw, weights_diff{2} ]= ...
    %                          vl_nnconv(bottom{1}, weights{1}, weights{2}, top_diff{1}, 'pad', l.convolution_param.pad, 'stride', l.convolution_param.stride);
    %         weights_diff{1} = weights_diff{1} + outputdzdw;
    %     elseif weights_diff_isCumulate(2)
    %         [ bottom_diff{1}, weights_diff{1}, outputdzdw ]= ...
    %                          vl_nnconv(bottom{1}, weights{1}, weights{2}, top_diff{1}, 'pad', l.convolution_param.pad, 'stride', l.convolution_param.stride);
    %         weights_diff{2} = weights_diff{2} + outputdzdw;
    %     else
    %         [ bottom_diff{1}, weights_diff{1}, weights_diff{2} ]= ...
    %                          vl_nnconv(bottom{1}, weights{1}, weights{2}, top_diff{1}, 'pad', l.convolution_param.pad, 'stride', l.convolution_param.stride);
    %     end

end