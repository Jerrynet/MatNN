function o = deconvolution(varargin)
%DECONVOLUTION

o.name         = 'Deconvolution';
o.generateLoss = false;
o.setup        = @setup;
o.forward      = @forward;
o.backward     = @backward;


default_weight_param = {
            'name' {'', ''}         ... %empty names means use autogenerated name
<<<<<<< HEAD
    'enable_terms' [true, true]     ...
       'generator' {@nn.generator.uniform, @nn.generator.constant} ...
       'generator_param' {[], []}   ... %default param
    'learningRate' single([1 1])    ...
     'weightDecay' single([1 1])
=======
    'enable_terms' [true, true]     ... 
       'generator' {@nn.generator.uniform, @nn.generator.constant} ...
       'generator_param' {[], []}   ... %default param
    'learningRate' single([1 1])    ...
     'weightDecay' single([1 1])  
>>>>>>> upstream/master
};
default_deconvolution_param = {
      'num_output' 1     ...
     'kernel_size' [3 3] ...
            'crop' [0 0] ...
      'upsampling' [1 1] ...
};

%
topSizes = [];

    function [resource, topSizes, param] = setup(l, bottomSizes)
        % resource only have .weights
        % if you have other outputs you want to save or share
        % you can set its learning rate to zero to prevent update


        if isfield(l, 'weight_param')
            wp1 = nn.utils.vararginHelper(default_weight_param, l.weight_param);
        else
            wp1 = nn.utils.vararginHelper(default_weight_param, default_weight_param);
        end
        if isfield(l, 'deconvolution_param')
            wp2 = nn.utils.vararginHelper(default_deconvolution_param, l.deconvolution_param);
        else
            wp2 = nn.utils.vararginHelper(default_deconvolution_param, default_deconvolution_param);
        end
        if ~any(wp1.enable_terms)
            error('At least enable one weight.');
        end


        assert(numel(l.bottom)==1);
        assert(numel(l.top)==1);


        kernel_size = wp2.kernel_size;
        if numel(kernel_size) == 1
            kernel_size = [kernel_size, kernel_size];
        end
        stride_size = wp2.upsampling;
        if numel(stride_size) == 1
            stride_size = [stride_size, stride_size];
        end
        pad_size = wp2.crop;
        if numel(pad_size) == 1
            pad_size = [pad_size, pad_size, pad_size, pad_size];
        elseif numel(pad_size) == 2
            pad_size = [pad_size(1), pad_size(1), pad_size(2), pad_size(2)];
        end


        resource.weight = {[],[]};
        btmSize = bottomSizes{1};
        topSizes = {[floor([(btmSize(1)-1)*stride_size(1)-pad_size(1)-pad_size(2)+kernel_size(1), ...
                           (btmSize(2)-1)*stride_size(2)-pad_size(3)-pad_size(4)+kernel_size(2)]), ...
                            wp2.num_output, btmSize(4)]};


        if wp1.enable_terms(1)
            resource.weight{1} = wp1.generator{1}([kernel_size(1), kernel_size(2), wp2.num_output, bottomSizes{1}(3)], wp1.generator_param{1});
        end

        if wp1.enable_terms(2)
            resource.weight{2} = wp1.generator{2}([1, wp2.num_output], wp1.generator_param{2});
        end

        %return updated param
        param.weight_param = wp1;
        param.deconvolution_param = wp2;
    end


    function [top, weights, misc] = forward(opts, l, weights, misc, bottom, top)
        top{1} = vl_nnconvt(bottom{1}, weights{1}, weights{2}, 'crop', l.deconvolution_param.crop, 'upsample', l.deconvolution_param.upsampling);
    end


    function [bottom_diff, weights_diff, misc] = backward(opts, l, weights, misc, bottom, top, top_diff, weights_diff, weights_diff_isCumulate)

        if weights_diff_isCumulate(1) && weights_diff_isCumulate(2)
            [ bottom_diff{1}, a, b ]= ...
                             vl_nnconvt(bottom{1}, weights{1}, weights{2}, top_diff{1}, 'crop', l.deconvolution_param.crop, 'upsample', l.deconvolution_param.upsampling);
            weights_diff{1} = weights_diff{1} + a;
            weights_diff{2} = weights_diff{2} + b;
        elseif weights_diff_isCumulate(1)
            [ bottom_diff{1}, outputdzdw, weights_diff{2} ]= ...
                             vl_nnconvt(bottom{1}, weights{1}, weights{2}, top_diff{1}, 'Crop', l.deconvolution_param.crop, 'Upsample', l.deconvolution_param.upsampling);
            weights_diff{1} = weights_diff{1} + outputdzdw;
        elseif weights_diff_isCumulate(2)
            [ bottom_diff{1}, weights_diff{1}, outputdzdw ]= ...
                             vl_nnconvt(bottom{1}, weights{1}, weights{2}, top_diff{1}, 'Crop', l.deconvolution_param.crop, 'Upsample', l.deconvolution_param.upsampling);
            weights_diff{2} = weights_diff{2} + outputdzdw;
        else
            [ bottom_diff{1}, weights_diff{1}, weights_diff{2} ]= ...
                             vl_nnconvt(bottom{1}, weights{1}, weights{2}, top_diff{1}, 'Crop', l.deconvolution_param.crop, 'Upsample', l.deconvolution_param.upsampling);
        end

    end

end