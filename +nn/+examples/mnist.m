function mnist()

conf = nn.examples.config();
trainer = nn.nn('MNIST');
batchSize = 100;

trainer.add({
    'type' 'data.MNIST'...
    'name' 'data'...
    'top' {'data', 'label'} ...
    'data_param' {
                'src' conf.mnistPath ...
        'root_folder' ''       ...
         'batch_size' batchSize ...
               'full' false  ...
            'shuffle' true   ...
        } ...
    'mnist_param' {
           'type' 'train' ...
        } ...
    'phase' 'train'
    });
trainer.add({
    'type' 'data.MNIST'...
    'name' 'data'...
    'top' {'data', 'label'} ...
    'data_param' {
                'src' conf.mnistPath ...
        'root_folder' ''       ...
         'batch_size' batchSize ...
               'full' false  ...
            'shuffle' true   ...
        } ...
    'mnist_param' {
           'type' 'test' ...
        } ...
    'phase' 'test'
    });
trainer.add({
    'type'   'Conv'...
    'name'   'conv1'...
    'bottom' 'data' ...
    'top'    'conv1'...
    'conv_param' {
        'num_output'  20 ...
        'kernel_size' 5  ...
        'pad'         0  ...
        'stride'      1  ...
        }...
    'weight_param' {
        'generator'   {@nn.generator.gaussian, @nn.generator.constant} ...
        'generator_param' {{'mean', 0, 'std', 0.01}, []}
        }
    });
trainer.add({
    'type'   'Pooling'...
    'name'   'pool1'...
    'bottom' 'conv1'...
    'top'    'pool1'...
    'pooling_param' {
        'method'      'max' ...
        'kernel_size' 2  ...
        'pad'         0  ...
        'stride'      2  ...
        }...
    });
trainer.add({
    'type'   'Conv'...
    'name'   'conv2'...
    'bottom' 'pool1' ...
    'top'    'conv2'...
    'conv_param' {
        'num_output'  50 ...
        'kernel_size' 5  ...
        'pad'         0  ...
        'stride'      1  ...
        }...
    'weight_param' {
        'generator'   {@nn.generator.gaussian, @nn.generator.constant} ...
        'generator_param' {{'mean', 0, 'std', 0.01}, []}
        }
    });
trainer.add({
    'type'   'Pooling'...
    'name'   'pool2'...
    'bottom' 'conv2'...
    'top'    'pool2'...
    'pooling_param' {
        'method'      'max' ...
        'kernel_size' 2  ...
        'pad'         0  ...
        'stride'      2  ...
        }...
    });
trainer.add({
    'type'   'Conv'...
    'name'   'conv3'...
    'bottom' 'pool2' ...
    'top'    'conv3'...
    'conv_param' {
        'num_output'  500 ...
        'kernel_size' 4  ...
        'pad'         0  ...
        'stride'      1  ...
        }...
    'weight_param' {
        'generator'   {@nn.generator.gaussian, @nn.generator.constant} ...
        'generator_param' {{'mean', 0, 'std', 0.01}, []}
        }
    });
trainer.add({
    'type'   'ReLU'...
    'name'   'relu1'...
    'bottom' 'conv3'...
    'top'    'relu1'...
    });
trainer.add({
    'type'   'Conv'...
    'name'   'fc4'...
    'bottom' 'relu1' ...
    'top'    'fc4'...
    'conv_param' {
        'num_output'  10 ...
        'kernel_size' 1  ...
        'pad'         0  ...
        'stride'      1  ...
        }...
    'weight_param' {
        'generator'   {@nn.generator.gaussian, @nn.generator.constant} ...
        'generator_param' {{'mean', 0, 'std', 0.01}, []}
        }
    });
trainer.add({
    'type'   'loss.SoftMaxLoss'...
    'name'   'loss'...
    'bottom' {'fc4', 'label'}...
    'top'    'loss'...
    'phase'  'train'...
    });
trainer.add({
    'type'   'Accuracy'...
    'name'   'accuracy'...
    'bottom' {'fc4', 'label'}...
    'top'    {'accuracy', 'meanClassAcc'}...
    'accuracy_param' {
        'meanClassAcc' true ...
        }...
    'phase'  'test'...
    });


trainer.setPhaseOrder('train', 'test');
trainer.setRepeat(5);
trainer.setSavePath(fullfile('data','exp'));
trainer.setGpu(1);
trainer.setShowDate(false);

trainOp.numToNext          = 600;  
trainOp.numToSave          = 600*conf.save;  
trainOp.displayIter        = 1;
trainOp.learningRateSteps  = 600;
trainOp.learningRatePolicy = @lrPolicy;
trainer.setPhasePara('train', trainOp);

testOp.numToNext           = 100;
testOp.numToSave           = [];
testOp.displayIter         = 100;
testOp.showFirstIter       = false;
testOp.learningRate        = 0;
trainer.setPhasePara('test', testOp);

trainer.run();

end

function res = lrPolicy(globalIterNum, currentPhaseTotalIter, lr, gamma, power, steps)
     res = lr*(gamma^floor((currentPhaseTotalIter-1)/steps));
end
