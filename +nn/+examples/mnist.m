function mnist()

conf = nn.examples.config();
trainer = nn.nn('MNIST');
batchSize = 100;

trainer.add({
    'type' 'data.MNIST'...
    'name' 'data_train'...
    'top' {'data', 'label'} ...
    'data_param' {
                'src' conf.mnistPath ...
        'root_folder' ''       ...
         'batch_size' batchSize ...
               'full' false  ...
            'shuffle' true   ...
        } ...
    'mnist_param' {
           'type' 'train' ...
        } ...
    });
trainer.add({
    'type' 'data.MNIST'...
    'name' 'data_test'...
    'top' {'data', 'label'} ...
    'data_param' {
                'src' conf.mnistPath ...
        'root_folder' ''       ...
         'batch_size' batchSize ...
               'full' false  ...
            'shuffle' true   ...
        } ...
    'mnist_param' {
           'type' 'test' ...
        } ...
    });
trainer.add({
    'type'   'Conv'...
    'name'   'conv1'...
    'bottom' 'data' ...
    'top'    'conv1'...
    'conv_param' {
        'num_output'  20 ...
        'kernel_size' 5  ...
        'pad'         0  ...
        'stride'      1  ...
        }...
    'weight_param' {
        'generator'   {@nn.generator.gaussian, @nn.generator.constant} ...
        'generator_param' {{'mean', 0, 'std', 0.01}, []}
        }
    });
trainer.add({
    'type'   'Pooling'...
    'name'   'pool1'...
    'bottom' 'conv1'...
    'top'    'pool1'...
    'pooling_param' {
        'method'      'max' ...
        'kernel_size' 2  ...
        'pad'         0  ...
        'stride'      2  ...
        }...
    });
trainer.add({
    'type'   'Conv'...
    'name'   'conv2'...
    'bottom' 'pool1' ...
    'top'    'conv2'...
    'conv_param' {
        'num_output'  50 ...
        'kernel_size' 5  ...
        'pad'         0  ...
        'stride'      1  ...
        }...
    'weight_param' {
        'generator'   {@nn.generator.gaussian, @nn.generator.constant} ...
        'generator_param' {{'mean', 0, 'std', 0.01}, []}
        }
    });
trainer.add({
    'type'   'Pooling'...
    'name'   'pool2'...
    'bottom' 'conv2'...
    'top'    'pool2'...
    'pooling_param' {
        'method'      'max' ...
        'kernel_size' 2  ...
        'pad'         0  ...
        'stride'      2  ...
        }...
    });
trainer.add({
    'type'   'Conv'...
    'name'   'conv3'...
    'bottom' 'pool2' ...
    'top'    'conv3'...
    'conv_param' {
        'num_output'  500 ...
        'kernel_size' 4  ...
        'pad'         0  ...
        'stride'      1  ...
        }...
    'weight_param' {
        'generator'   {@nn.generator.gaussian, @nn.generator.constant} ...
        'generator_param' {{'mean', 0, 'std', 0.01}, []}
        }
    });
trainer.add({
    'type'   'ReLU'...
    'name'   'relu1'...
    'bottom' 'conv3'...
    'top'    'relu1'...
    });
trainer.add({
    'type'   'Conv'...
    'name'   'fc4'...
    'bottom' 'relu1' ...
    'top'    'fc4'...
    'conv_param' {
        'num_output'  10 ...
        'kernel_size' 1  ...
        'pad'         0  ...
        'stride'      1  ...
        }...
    'weight_param' {
        'generator'   {@nn.generator.gaussian, @nn.generator.constant} ...
        'generator_param' {{'mean', 0, 'std', 0.01}, []}
        }
    });
trainer.add({
    'type'   'loss.SoftMaxLoss'...
    'name'   'loss'...
    'bottom' {'fc4', 'label'}...
    'top'    'loss'...
    });
trainer.add({
    'type'   'Accuracy'...
    'name'   'accuracy'...
    'bottom' {'fc4', 'label'}...
    'top'    {'accuracy', 'meanClassAcc'}...
    'accuracy_param' {
        'meanClassAcc' true ...
        }...
    });

trainer.flowOrder = {'train'};
trainer.repeat    = 5;
trainer.savePath  = fullfile('data','exp');
trainer.gpu       = 1;
trainer.showDate  = false;

trainOp.iter        = 600;  
trainOp.numToSave   = 600*conf.save;  
trainOp.displayIter = 1;
trainOp.lrGamma     = 0.8;
trainOp.lrSteps     = 600;
trainOp.lrPolicy    = @lrPolicy;

testOp.iter          = 100;
testOp.numToSave     = [];
testOp.displayIter   = 100;
testOp.showFirstIter = false;
testOp.lr            = 0;

trainLayers = trainer.getLayerIDs('data_train', 'conv1', 'pool1', 'conv2', 'pool2', 'conv3', 'relu1', 'fc4', 'loss');
testLayers  = trainer.getLayerIDs('data_test' , 'conv1', 'pool1', 'conv2', 'pool2', 'conv3', 'relu1', 'fc4', 'accuracy');

trainer.addFlow('train', trainOp, trainLayers);
trainer.addFlow('test',  testOp,  testLayers );

%trainer.load(600);

trainer.run();

end

function res = lrPolicy(globalIterNum, currentPhaseTotalIter, lr, gamma, power, steps)
     res = lr*(gamma^floor((currentPhaseTotalIter-1)/steps));
end
